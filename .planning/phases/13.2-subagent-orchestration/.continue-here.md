---
phase: 13.2-subagent-orchestration
task: background-agent-architecture
total_tasks: N/A
status: in_progress
last_updated: 2026-02-06T04:50:00Z
---

<current_state>
Replaced Task-tool subagent architecture with daemon-managed `--resume` background agents. Full pipeline works end-to-end in Docker. One remaining issue: Telegram notification delivery for long summaries (message splitting fix deployed but untested).
</current_state>

<completed_work>

**Background Agent Architecture (this session):**

- New `src/mcp-server/tools/background.ts` — `start_background_task` MCP tool (pure signal)
- New `src/daemon/background-agent.ts` — `spawnBackgroundAgent()` via `claude --resume`, task file lifecycle, no timeout
- MCP server registration, daemon exports
- Removed ALL Task-tool plumbing from spawner.ts, streaming.ts, gateway.ts
- Added `--disallowedTools Task,TaskOutput` everywhere
- **Critical fix:** MCP tool use tracking — `assistant` message events now captured (was root cause of `toolUseCount: 0`)
- Added `session_id` to `StreamResult` for `--resume`
- Gateway: `maybeSpawnBackgroundAgent()` detects MCP tool call, spawns background agent
- Rewrote orchestration instructions — aggressive dispatcher prompt ("YOU WILL BE KILLED")
- Config schema: removed `taskListIdPrefix`, default model → `claude-opus-4-6`
- Config seeding: `loadJsonConfig()` writes defaults to disk if missing
- HEARTBEAT.md moved to `identity/` folder
- docker-compose.yml: bind mount `./data` instead of named volume
- task-watcher: message splitting for summaries >4096 chars
- Removed debug logging from streaming.ts

**Verified working (Docker test):**

- Dispatcher called `start_background_task` in 12s
- Background agent ran ~2 min, did web research, produced 5.5KB budget analysis
- Task file lifecycle: active → completed (status: "success")
- Task watcher detected completion but notification failed (message too long — now fixed)

</completed_work>

<remaining_work>

- Verify Telegram notification delivery with split messages (task moved back to completed/ for retry)
- Run another full end-to-end test
- Commit all changes
- Update STATE.md
- Phase 14 (Testing Framework) not started
  </remaining_work>

<decisions_made>

- `--resume` over Task tool: Task tool spawns child processes that die with parent (single-turn `-p` mode)
- MCP tool as signal: Tool returns "queued" text. Daemon detects tool call from stream events, does real work
- No timeout on background agents: User wants them to run indefinitely
- Stream event format: MCP tools emit `type: "assistant"` with `message.content[].type: "tool_use"`, NOT `content_block_start/delta/stop`. Both parsers now handle both formats
- Aggressive dispatcher prompt: Required after 3 iterations. Claude was faking delegation or going heads-down
- Bind mount `./data` over named volume: User wants to see files on host
- Default model: `claude-opus-4-6` (higher prompt adherence)
  </decisions_made>

<blockers>
- Notification delivery untested after message-splitting fix
</blockers>

<context>
Architecture: dispatcher (90s timeout, streaming) → calls MCP tool → daemon captures from stream events → spawns `claude --resume <session_id>` → background agent runs indefinitely → writes completed task file → task-watcher polls → Telegram notification.

Key debugging discovery: Claude CLI stream-json uses DIFFERENT event formats for built-in vs MCP tool use. Built-in: granular `content_block_start/delta/stop`. MCP: full `assistant` message objects. Our parsers only handled the former — invisible MCP tool calls was the root cause of 4 failed test iterations.

Files modified (13 files, 2 new):

- docker-compose.yml, src/config/json.ts, src/config/schema.ts
- src/daemon/gateway.ts, src/daemon/index.ts, src/daemon/spawner.ts
- src/daemon/background-agent.ts (NEW), src/daemon/task-watcher.ts
- src/heartbeat/executor.ts, src/mcp-server/index.ts
- src/mcp-server/tools/background.ts (NEW)
- src/memory/context.ts, src/telegram/streaming.ts
  </context>

<next_action>

1. Check ./data/tasks/notified/ — did the retry notification get delivered?
2. If not, debug task-watcher message splitting
3. Fresh end-to-end test
4. Commit all changes
5. Update STATE.md
   </next_action>
