---
phase: 10-telegram-streaming
plan: 02
type: execute
wave: 2
depends_on: ["10-01"]
files_modified:
  - src/telegram/streaming.ts
  - src/daemon/gateway.ts
autonomous: true

must_haves:
  truths:
    - "User sees draft message updating as Claude generates response"
    - "Draft updates are throttled to avoid API rate limits"
    - "Final message replaces draft when streaming completes"
    - "Streaming can be disabled via config (falls back to batch)"
  artifacts:
    - path: "src/telegram/streaming.ts"
      provides: "streamToTelegram and canStreamToChat functions"
      exports: ["streamToTelegram", "canStreamToChat"]
    - path: "src/daemon/gateway.ts"
      provides: "Gateway with streaming/batch path selection"
      contains: "streamToTelegram"
  key_links:
    - from: "src/daemon/gateway.ts"
      to: "src/telegram/streaming.ts"
      via: "import and call streamToTelegram"
      pattern: "streamToTelegram.*chatId"
    - from: "src/telegram/streaming.ts"
      to: "bot.api.sendMessageDraft"
      via: "throttled draft updates"
      pattern: "sendMessageDraft.*draftId"
    - from: "src/telegram/streaming.ts"
      to: "bot.api.sendMessage"
      via: "final message after stream"
      pattern: "sendMessage.*result"
---

<objective>
Integrate streaming into gateway and implement Telegram draft streaming.

Purpose: Users experience real-time response generation - seeing Claude's reply build character-by-character in a draft bubble, then receiving the final message.

Output:

- Gateway uses streaming when available, batch when not
- Draft updates sent via sendMessageDraft, throttled to avoid 429s
- Final message sent after stream completes
  </objective>

<execution_context>
@/home/soham/.claude/get-shit-done/workflows/execute-plan.md
@/home/soham/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/10-telegram-streaming/10-RESEARCH.md
@.planning/phases/10-telegram-streaming/10-01-SUMMARY.md

# Files to modify

@src/telegram/streaming.ts
@src/daemon/gateway.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add Telegram draft streaming functions</name>
  <files>src/telegram/streaming.ts</files>
  <action>
Extend streaming.ts with Telegram-specific functions:

1. **Add imports:**

   ```typescript
   import { Bot } from "grammy";
   ```

2. **canStreamToChat(bot, chatId)** - Check if draft streaming is available:

   ```typescript
   export async function canStreamToChat(
     bot: Bot,
     chatId: number,
   ): Promise<boolean> {
     try {
       const chat = await bot.api.getChat(chatId);
       // Draft streaming requires private chat with topics enabled
       return chat.type === "private" && Boolean(chat.has_topics_enabled);
     } catch {
       return false;
     }
   }
   ```

   NOTE: Per RESEARCH.md, sendMessageDraft only works in private chats with forum topics enabled. User must enable "Threaded Mode" in BotFather for their bot.

3. **streamToTelegram(bot, chatId, prompt, config, options?)** - Main streaming function:

   ```typescript
   let draftIdCounter = 0;

   export interface StreamToTelegramOptions {
     model?: string;
     additionalInstructions?: string;
     messageThreadId?: number;
   }

   export async function streamToTelegram(
     bot: Bot,
     chatId: number,
     prompt: string,
     config: StreamConfig,
     options?: StreamToTelegramOptions,
   ): Promise<{ result: string; cost_usd: number }> {
     const log = createChildLogger("streaming");
     const draftId = ++draftIdCounter;
     const controller = new AbortController();

     let accumulated = "";
     let lastUpdateTime = 0;

     // Callback for each text chunk - sends throttled draft updates
     const onChunk = async (text: string): Promise<void> => {
       accumulated += text;

       const now = Date.now();
       if (now - lastUpdateTime >= config.throttleMs) {
         try {
           await bot.api.sendMessageDraft(chatId, draftId, accumulated, {
             message_thread_id: options?.messageThreadId,
           });
           lastUpdateTime = now;
         } catch (err) {
           log.warn({ err, chatId }, "Draft update failed, continuing");
         }
       }
     };

     try {
       // Call streamClaudeResponse with callback
       const result = await streamClaudeResponse(
         prompt,
         {
           model: options?.model,
           additionalInstructions: options?.additionalInstructions,
           signal: controller.signal,
         },
         onChunk,
       );

       // Send final draft update (ensures latest content shown)
       await bot.api
         .sendMessageDraft(chatId, draftId, result.result, {
           message_thread_id: options?.messageThreadId,
         })
         .catch(() => {});

       return result;
     } catch (err) {
       controller.abort();

       // On error, still try to send accumulated partial result
       if (accumulated.length > 0) {
         log.error({ err, chatId }, "Stream error, returning partial result");
         return { result: accumulated, cost_usd: 0 };
       }

       throw err;
     }
   }
   ```

   Key points:
   - **Callback-based**: Uses onChunk callback with streamClaudeResponse (not generator)
   - **Throttled updates**: Sends draft only if throttleMs elapsed since last update
   - **Draft ID**: Simple incrementing counter (Telegram overwrites by ID)
   - **Error handling**: Returns partial result on error if any accumulated
   - **cost_usd**: Correctly returned from streamClaudeResponse Promise

4. **Update exports in src/telegram/index.ts:**
   ```typescript
   export {
     streamClaudeResponse,
     streamToTelegram,
     canStreamToChat,
     type StreamConfig,
     type StreamOptions,
     type StreamResult,
     type StreamToTelegramOptions,
   } from "./streaming.js";
   ```
   </action>
   <verify>

- `npm run build` compiles
- streaming.ts exports canStreamToChat and streamToTelegram
  </verify>
  <done>
- canStreamToChat checks for private chat with topics
- streamToTelegram uses callback pattern with streamClaudeResponse
- Sends throttled draft updates via sendMessageDraft
- Returns { result, cost_usd } from Promise (not generator)
  </done>
  </task>

<task type="auto">
  <name>Task 2: Integrate streaming into gateway processMessage</name>
  <files>src/daemon/gateway.ts</files>
  <action>
Modify processMessage() in gateway.ts to use streaming when available:

1. Add imports at top:

   ```typescript
   import { streamToTelegram, canStreamToChat } from "../telegram/index.js";
   ```

2. In processMessage(), after building effectiveText and before the Claude query, add streaming path:

   ```typescript
   // After: const jsonConfig = getJsonConfig();
   // Before: const response = await queryClaudeCode(...)

   // Check if streaming is enabled and available
   const streamingEnabled = jsonConfig.streaming?.enabled ?? true;
   const canStream =
     streamingEnabled && (await canStreamToChat(bot, msg.chatId));

   if (canStream) {
     // === STREAMING PATH ===
     log.info({ chatId: msg.chatId }, "Using streaming mode");

     try {
       const streamResult = await streamToTelegram(
         bot,
         msg.chatId,
         effectiveText,
         jsonConfig.streaming ?? { enabled: true, throttleMs: 500 },
         {
           model: jsonConfig.model,
           additionalInstructions,
         },
       );

       // Stop typing indicator
       clearInterval(typingInterval);

       // Mark as complete
       queue.complete(msg.id);

       // Send final message (replaces draft in UI)
       if (streamResult.result) {
         await splitAndSend(msg.chatId, streamResult.result);
       }

       // Invalidate identity cache
       invalidateIdentityCache();

       // Notify user of non-fatal media errors
       if (mediaErrors.length > 0) {
         await bot.api.sendMessage(
           msg.chatId,
           `Note: Some media could not be processed: ${mediaErrors.join(". ")}`,
         );
       }

       const duration = Date.now() - startTime;
       log.info(
         {
           chatId: msg.chatId,
           queueId: msg.id,
           duration,
           cost: streamResult.cost_usd,
           streaming: true,
         },
         "Message processed (streaming)",
       );

       // Auto-commit
       const committed = await autoCommitChanges();
       if (committed) {
         log.info({ queueId: msg.id }, "Auto-committed Claude file changes");
       }

       return; // Exit early - streaming handled everything
     } catch (err) {
       // Streaming failed - fall through to batch mode
       log.warn(
         { err, chatId: msg.chatId },
         "Streaming failed, falling back to batch",
       );
     }
   }

   // === BATCH PATH (existing code) ===
   // ... existing queryClaudeCode logic ...
   ```

3. Key integration points:
   - Check `jsonConfig.streaming?.enabled` (default true)
   - Call `canStreamToChat()` to verify draft support
   - Use `streamToTelegram()` for streaming path
   - Fall back to batch (existing `queryClaudeCode`) on streaming failure
   - Send final message via `splitAndSend()` after streaming completes
   - Keep typing indicator until streaming starts (then drafts show progress)

4. The batch path (existing code) remains unchanged as fallback.
   </action>
   <verify>

- `npm run build` compiles
- Gateway imports streaming functions
- processMessage has both streaming and batch paths
  </verify>
  <done>
- Gateway checks streaming config and chat capability
- Uses streamToTelegram when streaming available
- Falls back to queryClaudeCode (batch) when not
- Final message sent after stream completes
- cost_usd correctly logged from streamResult
  </done>
  </task>

<task type="auto">
  <name>Task 3: Handle streaming edge cases and error recovery</name>
  <files>src/telegram/streaming.ts, src/daemon/gateway.ts</files>
  <action>
Add robustness for production use:

1. **In streaming.ts - Timeout handling:**
   Add timeout to streamClaudeResponse (use 5 minute default like spawner.ts):

   ```typescript
   const DEFAULT_TIMEOUT = 300000; // 5 minutes

   // In streamClaudeResponse, add timeout:
   export async function streamClaudeResponse(
     prompt: string,
     options: StreamOptions,
     onChunk: (text: string) => void,
   ): Promise<StreamResult> {
     // ... existing setup ...

     return new Promise((resolve, reject) => {
       const claude = spawn("claude", args, { ... });

       let timedOut = false;

       // Set up timeout
       const timeoutId = setTimeout(() => {
         timedOut = true;
         claude.kill("SIGTERM");
         setTimeout(() => {
           if (!claude.killed) claude.kill("SIGKILL");
         }, 5000);
       }, DEFAULT_TIMEOUT);

       // ... existing line parsing ...

       rl.on("close", () => {
         clearTimeout(timeoutId);

         if (timedOut) {
           // Return partial result on timeout
           log.warn({ resultLength: accumulated.length }, "Stream timed out");
           resolve({ result: accumulated, cost_usd: 0 });
         } else {
           log.info({ ... }, "Stream completed");
           resolve({ result: accumulated, cost_usd: costUsd });
         }
       });

       // ... rest of error handling ...
     });
   }
   ```

2. **In gateway.ts - Graceful degradation:**
   - If canStreamToChat returns false, log reason and use batch
   - If streamToTelegram throws, catch and fall back to batch
   - This is already handled in Task 2 but ensure try/catch is robust

3. **Ensure final message ALWAYS sent:**
   - Draft disappears if not followed by real message
   - Even on error, send accumulated text or error indicator

   ```typescript
   // After streamToTelegram in gateway:
   if (!streamResult.result) {
     await bot.api.sendMessage(msg.chatId, "[Empty response]");
   }
   ```

4. **In streamToTelegram - Error handling already in place:**
   - On error, returns partial result if accumulated > 0
   - Otherwise re-throws for gateway to catch and fall back
     </action>
     <verify>

- `npm run build` compiles
- Error paths log appropriately
- Partial results preserved on timeout/error
  </verify>
  <done>
- Streaming errors caught and logged
- Partial results returned on failure
- Final message always sent (even if empty/error)
- Timeout handling consistent with batch spawner
  </done>
  </task>

</tasks>

<verification>
1. Build passes: `npm run build`
2. Gateway has streaming integration
3. Streaming module exports all needed functions
4. Error handling in place for graceful degradation

Manual testing (user should verify):

- Enable forum topics on bot via BotFather
- Send message in private chat
- Observe draft appearing and updating
- Final message replaces draft
  </verification>

<success_criteria>

- STRM-01: Telegram draft streaming via sendMessageDraft - DONE
- STRM-02: Updates throttled (configurable, default 500ms) - DONE
- STRM-03: Final message sent after streaming completes - DONE
- STRM-04: Streaming configurable (can be disabled via config) - DONE

User experience:

1. Send message to bot
2. See draft bubble appear with first tokens
3. Watch draft update every 500ms with new content
4. Final message appears when complete
   </success_criteria>

<output>
After completion, create `.planning/phases/10-telegram-streaming/10-02-SUMMARY.md`
</output>
